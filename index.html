<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <meta name="title" content="Simultaneous Action and Grasp Feasibility Prediction for Task and Motion Planning through Multi-Task Learning - Smail Ait Bouhsain, Rachid Alami, Thierry Simeon">
  <meta name="description" content="This paper introduces AGFP-Net, a multi-task neural network for predicting action and grasp feasibility, and an enhanced TAMP algorithm to address the combinatorial complexity of task and motion planning in robotics.">
  <meta name="keywords" content="task and motion planning, TAMP, 3D environments, action feasibility prediction, deep neural networks, robotics, scene representation, manipulation planning, geometric planning, machine learning, artificial intelligence">
  <meta name="author" content="Smail Ait Bouhsain, Rachid Alami, Thierry Simeon">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <meta property="og:site_name" content="LAAS-CNRS">
  <meta property="og:title" content="Simultaneous Action and Grasp Feasibility Prediction for Task and Motion Planning through Multi-Task Learning">
  <meta property="og:description" content="This paper introduces AGFP-Net, a multi-task neural network for predicting action and grasp feasibility, and an enhanced TAMP algorithm to address the combinatorial complexity of task and motion planning in robotics.">
  <meta property="og:url" content="https://smail8.github.io/action-grasp-feasibility-prediction/">
  <meta property="og:image" content="https://github.com/Smail8/action-grasp-feasibility-prediction/tree/master/static/images/poster.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="Simultaneous Action and Grasp Feasibility Prediction for Task and Motion Planning through Multi-Task Learning - Research Preview">
  <meta property="article:published_time" content="2023-10-01T00:00:00.000Z">
  <meta property="article:author" content="Smail Ait Bouhsain">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="task and motion planning">
  <meta property="article:tag" content="action and grasp feasibility prediction">
  <meta property="article:tag" content="robotics">
  <meta property="article:tag" content="deep learning">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@LaasCNRS">
  <meta name="twitter:creator" content="@Sm1Le8B">
  <meta name="twitter:title" content="Simultaneous Action and Grasp Feasibility Prediction for Task and Motion Planning through Multi-Task Learning">
  <meta name="twitter:description" content="This paper introduces AGFP-Net, a multi-task neural network for predicting action and grasp feasibility, and an enhanced TAMP algorithm to address the combinatorial complexity of task and motion planning in robotics.">
  <meta name="twitter:image" content="https://github.com/Smail8/action-grasp-feasibility-prediction/tree/master/static/images/poster.png">
  <meta name="twitter:image:alt" content="Simultaneous Action and Grasp Feasibility Prediction for Task and Motion Planning through Multi-Task Learning - Research Preview">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="Simultaneous Action and Grasp Feasibility Prediction for Task and Motion Planning through Multi-Task Learning">
  <meta name="citation_author" content="Ait Bouhsain, Smail">
  <meta name="citation_author" content="Alami, Rachid">
  <meta name="citation_author" content="Siméon, Thierry">
  <meta name="citation_publication_date" content="2023">
  <meta name="citation_conference_title" content="IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2023)">
  <meta name="citation_pdf_url" content="https://github.com/Smail8/action-grasp-feasibility-prediction/tree/master/static/pdfs/paper.pdf">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">

  <title>Simultaneous Action and Grasp Feasibility Prediction for Task and Motion Planning through Multi-Task Learning - Ait Bouhsain, Smail, Alami, Rachid, Siméon, Thierry | Academic Research</title>
  
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/panda_icon.png">
  <link rel="apple-touch-icon" href="static/images/panda_icon.png">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "Simultaneous Action and Grasp Feasibility Prediction for Task and Motion Planning through Multi-Task Learning",
    "description": "This paper presents a novel approach for simultaneous action and grasp feasibility prediction in the context of task and motion planning. By leveraging multi-task learning, we aim to improve the efficiency and effectiveness of robotic planning systems.",
    "author": [
      {
        "@type": "Person",
        "name": "Ait Bouhsain, Smail",
        "affiliation": {
          "@type": "Organization",
          "name": "LAAS-CNRS"
        }
      },
      {
        "@type": "Person",
        "name": "Alami, Rachid",
        "affiliation": {
          "@type": "Organization",
          "name": "LAAS-CNRS"
        }
      },
      {
        "@type": "Person",
        "name": "Siméon, Thierry",
        "affiliation": {
          "@type": "Organization",
          "name": "LAAS-CNRS"
        }
      }
    ],
    "datePublished": "2023-10-01",
    "publisher": {
      "@type": "Organization",
      "name": "IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2023)"
    },
    "url": "https://smail8.github.io/action-grasp-feasibility-prediction/",
    "image": "https://github.com/Smail8/action-grasp-feasibility-prediction/tree/master/static/images/poster.png",
    "keywords": [
      "task and motion planning",
      "TAMP",
      "3D environments",
      "action feasibility prediction",
      "deep neural networks",
      "robotics",
      "scene representation",
      "manipulation planning",
      "geometric planning",
      "machine learning",
      "artificial intelligence"
    ],
    "abstract": "In this paper, we address task and motion planning (TAMP) which is an important yet challenging robotics problem. It is known to suffer from the high combinatorial complexity of discrete search, often requiring a large number of geometric planning calls. We build upon recent works in TAMP by taking advantage of learning methods to provide action feasibility information as a heuristic to the symbolic planner, thus guiding it to a geometrically feasible solution and reducing geometric planning time. We propose AGFP-Net, a multi-task neural network predicting not only action feasibility, but also the feasibility of a set of grasp types. We also propose an improved feasibility-informed TAMP algorithm capable of solving more complex problems, and handling goals which are not fully specified. Comparative results obtained on different problems of varying complexity show that our method is able to greatly reduce task and motion planning time.",
    "citation": "@inproceedings{ait2023simultaneous,
      title={Simultaneous action and grasp feasibility prediction for task and motion planning through multi-task learning},
      author={Ait Bouhsain, Smail and Alami, Rachid and Simeon, Thierry},
      booktitle={2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
      pages={2042--2048},
      year={2023},
      organization={IEEE}
    }",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://smail8.github.io/action-grasp-feasibility-prediction/"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "AI for Robotics"
      },
      {
        "@type": "Thing", 
        "name": "Machine Learning"
      },
      {
        "@type": "Thing", 
        "name": "Task and Motion Planning"
      },
      {
        "@type": "Thing", 
        "name": "Deep Learning"
      }
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "LAAS-CNRS",
    "url": "https://www.laas.fr",
    "logo": "https://github.com/Smail8/action-feasibility-prediction/tree/master/static/images/laas_logo.png",
    "sameAs": [
      "https://twitter.com/LaasCNRS",
      "https://github.com/Smail8"
    ]
  }
  </script>
</head>

<body>
  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  <!-- More Works Dropdown -->
  <div class="more-works-container">
    <button class="more-works-btn" onclick="toggleMoreWorks()" title="View More Works from Our Lab">
      <i class="fas fa-flask"></i>
      More Works
      <i class="fas fa-chevron-down dropdown-arrow"></i>
    </button>
    <div class="more-works-dropdown" id="moreWorksDropdown">
      <div class="dropdown-header">
        <h4>More Works from Our Lab</h4>
        <button class="close-btn" onclick="toggleMoreWorks()">
          <i class="fas fa-times"></i>
        </button>
      </div>
      <div class="works-list">
        <a href="https://openreview.net/pdf?id=ajxAJ8GUX4" class="work-item" target="_blank">
          <div class="work-info">
            <h5>Learning Geometric Reasoning Networks for Robot Task and Motion Planning</h5>
            <p>We present Geometric Reasoning Networks (GRN), a graph neural network-based model for predicting action and grasp feasibility in Task and Motion Planning (TAMP). GRN reduces reliance on geometric planners by incorporating interpretability mechanisms such as inverse kinematics feasibility prediction and grasp obstruction estimation, enabling efficient and explainable planning in complex 3D environments.</p>
            <span class="work-venue">The Thirteenth International Conference on Learning Representations (ICLR 2025)</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
        <a href="https://ieeexplore.ieee.org/abstract/document/10802307" class="work-item" target="_blank">
          <div class="work-info">
            <h5>Extending Task and Motion Planning with Feasibility Prediction: Towards Multi-Robot Manipulation Planning of Realistic Objects</h5>
            <p>We introduce a multi-robot TAMP algorithm that leverages feasibility prediction to address complex manipulation tasks. Our approach extends previous methods by enabling the handling of mesh-shaped objects and collaborative multi-robot settings, demonstrating significant improvements over baseline methods.</p>
            <span class="work-venue">IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2024)</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
        <a href="https://ieeexplore.ieee.org/abstract/document/10161114" class="work-item" target="_blank">
          <div class="work-info">
            <h5>Learning to Predict Action Feasibility for Task and Motion Planning in 3D Environments</h5>
            <p>We introduce a novel approach for Task and Motion Planning (TAMP) in 3D environments, combining an efficient 3D scene representation with a deep neural network to predict action feasibility, significantly reducing geometric planning time by up to 90% on complex problems.</p>
            <span class="work-venue">2023 IEEE International Conference on Robotics and Automation (ICRA)</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
      </div>
    </div>
  </div>

  <main id="main-content">
    <section class="hero">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <h1 class="title is-1 publication-title">Simultaneous Action and Grasp Feasibility Prediction for Task and Motion Planning through Multi-Task Learning</h1>
              <div class="is-size-5 publication-authors">
                <span class="author-block"><a href="https://smail8.github.io" target="_blank">Smail Ait Bouhsain</a>,</span>
                <span class="author-block"><a href="https://www.laas.fr/en/homepages/rachid/" target="_blank">Rachid Alami</a>,</span>
                <span class="author-block"><a href="https://www.laas.fr/fr/annuaire/29" target="_blank">Thierry Siméon</a></span>
              </div>

              <div class="is-size-5 publication-authors">
                <span class="author-block">LAAS-CNRS<br>2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</span>
              </div>

              <div class="column has-text-centered">
                <div class="publication-links">
                  <span class="link-block">
                    <a href="https://ieeexplore.ieee.org/abstract/document/10341257" target="_blank" class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Paper</span>
                    </a>
                  </span>

                  <span class="link-block">
                    <a href="static/images/poster.png" target="_blank" class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-photo-video"></i>
                      </span>
                      <span>Poster</span>
                    </a>
                  </span>

                  <span class="link-block">
                    <a href="https://github.com/smail8/action-grasp-feasibility-prediction" target="_blank" class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Code</span>
                    </a>
                  </span>

                  <span class="link-block">
                    <a href="https://laas.hal.science/hal-04016581v1/document" target="_blank" class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="ai ai-hal"></i>
                      </span>
                      <span>HAL</span>
                    </a>
                  </span>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Teaser video-->
    <section class="hero teaser">
      <div class="container is-max-desktop">
        <div class="hero-body">
          <iframe width="100%" height="500px" src="https://www.youtube.com/embed/rhHO3fyEkis" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>      
          <h2 class="subtitle has-text-centered">
            Given a task and motion planning (TAMP) problem, our method leverages AGFP-Net, a multi-task neural network, to predict both action feasibility and the feasibility of various grasp types. These predictions are used as heuristics to guide the symbolic planner towards geometrically feasible solutions, significantly reducing the time spent on geometric planning. This approach enables the robot to solve complex manipulation tasks more efficiently, even when goals are not fully specified.
          </h2>
        </div>
      </div>
    </section>
    <!-- End teaser video -->

    <!-- Paper abstract -->
    <section class="section hero is-light">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Abstract</h2>
            <div class="content has-text-justified">
              <p>
                In this paper, we address task and motion plan-ning (TAMP) which is an important yet challenging robotics problem. It is known to suffer from the high combinatorial complexity of discrete search, often requiring a large number of geometric planning calls. We build upon recent works in TAMP by taking advantage of learning methods to provide action feasibility information as a heuristic to the symbolic planner, thus guiding it to a geometrically feasible solution and reducing geometric planning time. We propose AGFP-Net, a multi-task neural network predicting not only action feasibility, but also the feasibility of a set of grasp types. We also propose an improved feasibility-informed TAMP algorithm capable of solving more complex problems, and handling goals which are not fully specified. Comparative results obtained on different problems of varying complexity show that our method is able to greatly reduce task and motion planning time.
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!-- End paper abstract -->

    <!-- Neural Network Image -->
    <section class="section hero is-small">
      <div class="hero-body">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Proposed Model</h2>
            <figure class="image">
              <img src="static/images/model.png" alt="Diagram of the proposed neural network AGFPNet">
            </figure>
            <p class="subtitle">
              A visualization of the proposed neural network architecture used for action and grasp feasibility prediction.
            </p>
          </div>
        </div>
      </div>
    </section>
    <!-- End Neural Network Image -->

    <!-- Benchmarks Section -->
    <section class="section hero is-light">
      <div class="hero-body">
        <div class="container">
          <h2 class="title is-3 has-text-centered">Benchmarks</h2>
          <div class="columns is-centered">
            <div class="column is-half has-text-centered">
              <figure class="image"></figure>
                <img src="static/images/reorder.png" alt="Reorder Benchmark">
              </figure>
                <p class="subtitle"><strong>Reorder problem:</strong> Objects initially placed on a two-shelf cupboard must be moved to another cupboard in a different order, testing the algorithm's ability to handle grasp choices and infeasible placements under shelves.</p>
            </div>
          </div>
          <div class="columns is-centered">
            <div class="column is-half has-text-centered">
              <figure class="image"></figure>
                <img src="static/images/unpack.png" alt="Unpack Benchmark">
              </figure>
                <p class="subtitle"><strong>Unpack problem:</strong> Objects initially placed on a tray-like surface must be unpacked and ordered into a cupboard. The challenge lies in selecting feasible grasps due to the proximity of objects and the restricted goal placements under a shelf, which disallow top grasps.</p>
            </div>
          </div>
          <div class="columns is-centered">
            <div class="column is-half has-text-centered">
              <figure class="image"></figure>
                <img src="static/images/swap.png" alt="Swap Benchmark">
              </figure>
              <p class="subtitle"><strong>Swap problem:</strong> A set of objects are initially placed either on the table or on higher support surfaces, and the goal is to swap their poses. The challenge arises from the fact that the goal poses of objects are already occupied, requiring the use of intermediary placements to achieve the desired configuration.</p>
            </div>
          </div>
          <div class="columns is-centered">
            <div class="column is-half has-text-centered">
              <figure class="image"></figure>
                <img src="static/images/access.png" alt="Access Benchmark">
              </figure>
              <p class="subtitle"><strong>Access problem:</strong> The task involves moving a single object (red) to its goal placement while ensuring all other objects are returned to their initial positions. The challenge arises as each object blocks access to the next, requiring the robot to sequentially move blocking objects to temporary placements, position the red object, and then restore the moved objects in their original order.</p>
            </div>
          </div>
          <div class="columns is-centered">
            <div class="column is-half has-text-centered">
              <figure class="image"></figure>
                <img src="static/images/sort.png" alt="Sort Benchmark">
              </figure>
                <p class="subtitle"><strong>Sort problem:</strong> The task involves moving a set of objects from a shelf to one of two small tables based on their color. The challenge lies in placement sampling, as the planner must find feasible placements that allow all objects of the same color to fit on narrow surfaces. Additionally, the initial proximity of objects requires a specific order of movement. The problem is further complicated by the presence of blocking objects (orange) with unspecified goals on the tables.</p>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!-- End Benchmarks Section -->

    <!-- Results Section -->
    <section class="section hero is-small">
      <div class="hero-body">
        <div class="container">
          <h2 class="title is-3 has-text-centered">Results</h2>
          <div class="columns is-centered">
            <div class="column is-full has-text-centered">
              <p class="subtitle">Detailed planning times of our algorithm on the <strong>Reorder</strong>, <strong>Unpack</strong> and <strong>Swap</strong> problems with and without feasibility prediction, compared to <a href="https://smail8.github.io/action-feasibility-prediction/" target="_blank">our previous work</a>, averaged over 10 runs.</p>
            </div>
          </div>
          <div class="columns is-centered">
            <!-- First image -->
            <div class="column is-one-third has-text-centered">
              <figure class="image">
                <img src="static/images/results_reorder.png" alt="Result on the Reorder Problem">
              </figure>
                <p class="subtitle"><strong>Reorder Problem</strong></p>
            </div>
            <!-- Second image -->
            <div class="column is-one-third has-text-centered">
              <figure class="image">
                <img src="static/images/results_unpack.png" alt="Result on the Unpack Problem">
              </figure>
              <p class="subtitle"><strong>Unpack Problem</strong></p>
            </div>
            <!-- Third image -->
            <div class="column is-one-third has-text-centered">
              <figure class="image">
                <img src="static/images/results_swap.png" alt="Result on the Swap Problem">
              </figure>
              <p class="subtitle"><strong>Swap Problem</strong></p>
            </div>
          </div>
          <div class="columns is-centered" style="margin-top: 2rem;">
            <div class="column is-full has-text-centered">
              <p class="subtitle">Detailed planning times of our algorithm on the <strong>Access</strong> and <strong>Sort</strong> problems with and without <strong>AFP-Net</strong>, averaged over 10 runs.</p>
            </div>
          </div>
          <div class="columns is-centered">
            <!-- Fourth image -->
            <div class="column is-half has-text-centered">
              <figure class="image">
                <img src="static/images/results_access.png" alt="Result on the Access Problem">
              </figure>
              <p class="subtitle"><strong>Access Problem</strong></p>
            </div>
            <!-- Fifth image -->
            <div class="column is-half has-text-centered">
              <figure class="image">
                <img src="static/images/results_sort.png" alt="Result on the Sort Problem">
              </figure>
              <p class="subtitle"><strong>Sort Problem</strong></p>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!-- End Results Section -->

    <!-- Visualizations Section -->
    <section class="section hero is-light">
      <div class="hero-body">
        <div class="container">
          <h2 class="title is-3 has-text-centered">Visualizations</h2>
          <div class="columns is-centered">
            <div class="column is-full has-text-centered">
              <p class="subtitle">Plan execution visualizations for each problem.</p>
            </div>
          </div>
          <div class="columns is-centered">
            <!-- First GIF -->
            <div class="column is-one-third has-text-centered">
              <figure class="image">
                <img src="static/images/reorder5.gif" alt="Visualization of the solution to the Reorder Problem">
              </figure>
              <p class="subtitle"><strong>Reorder Problem</strong></p>
            </div>
            <!-- Second GIF -->
            <div class="column is-one-third has-text-centered">
              <figure class="image">
                <img src="static/images/unpack5.gif" alt="Visualization of the solution to the Unpack Problem">
              </figure>
              <p class="subtitle"><strong>Unpack Problem</strong></p>
            </div>
            <!-- Third GIF -->
            <div class="column is-one-third has-text-centered">
              <figure class="image">
                <img src="static/images/swap5.gif" alt="Visualization of the solution to the Swap Problem">
              </figure>
              <p class="subtitle"><strong>Swap Problem</strong></p>
            </div>
          </div>
          <div class="columns is-centered" style="margin-top: 2rem;">
            <!-- Fourth GIF -->
            <div class="column is-half has-text-centered">
              <figure class="image">
                <img src="static/images/access.gif" alt="Visualization of the solution to the Access Problem">
              </figure>
              <p class="subtitle"><strong>Access Problem</strong></p>
            </div>
            <!-- Fifth GIF -->
            <div class="column is-half has-text-centered">
              <figure class="image">
                <img src="static/images/sort.gif" alt="Visualization of the solution to the Sort Problem">
              </figure>
              <p class="subtitle"><strong>Sort Problem</strong></p>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!-- End Visualizations Section -->

    <!--BibTex citation -->
    <section class="section" id="BibTeX">
      <div class="container is-max-desktop content">
        <div class="bibtex-header">
          <h2 class="title">BibTeX</h2>
          <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
            <i class="fas fa-copy"></i>
            <span class="copy-text">Copy</span>
          </button>
        </div>
        <pre id="bibtex-code">
          <code>
            @inproceedings{ait2023simultaneous,
              title={Simultaneous action and grasp feasibility prediction for task and motion planning through multi-task learning},
              author={Ait Bouhsain, Smail and Alami, Rachid and Simeon, Thierry},
              booktitle={2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
              pages={2042--2048},
              year={2023},
              organization={IEEE}
            }
          </code>
        </pre>
      </div>
    </section>
    <!--End BibTex citation -->
  </main>

  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
              You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
              Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- Statcounter tracking code -->
    
  <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->
  <!-- Default Statcounter code for AGFPNet (IROS23)
  https://smail8.github.io/action-grasp-feasibility-prediction/
  -->
  <script type="text/javascript">
    var sc_project=13197968; 
    var sc_invisible=1; 
    var sc_security="de60ebd2"; 
  </script>
  <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
  <noscript>
    <div class="statcounter">
      <a title="Web Analytics" href="https://statcounter.com/" target="_blank">
        <img class="statcounter" src="https://c.statcounter.com/13197968/0/de60ebd2/1/" alt="Web Analytics" referrerPolicy="no-referrer-when-downgrade">
      </a>
    </div>
  </noscript>
  <!-- End of Statcounter Code -->

</body>
</html>
